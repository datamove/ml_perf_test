{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of different cosine similarity implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "\n",
    "Cosine similarity is widely used in text comparision tasks. The texts are first turned into a term frequency matrix (TF), or TF-IDF. In such a form, each text is a vector in the vocabulary space. When two texts use a lot of common words with similar frequency, their vectors are nearly collinear, and cosine of the angle between them is close to 1.  On the opposite side, when two texts' words are mostly different, the vectors are ortogonal and cosine is close to 0. The formulae for cosine difference is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}cos(\\pmb x, \\pmb y) = \\frac {\\pmb x \\cdot \\pmb y}{||\\pmb x|| \\cdot ||\\pmb y||}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual task in recommendation system is to find texts most similar to a given one. For example, a job board site may want to display few similar vacancies to a user who applied to a particular job posting. \n",
    "\n",
    "In an offline batch, we can compute cosine similarity of every text to every other and look up for vacancies that are most similar to few interested to our user.\n",
    "\n",
    "Let's look at several possible implmentations of the cosine similarity.\n",
    "\n",
    "We'll be measuring execution speed with a help of a wrapper around Python's timeit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeit.template = \"\"\"\n",
    "def inner(_it, _timer{init}):\n",
    "    {setup}\n",
    "    _t0 = _timer()\n",
    "    for _i in _it:\n",
    "        retval = {stmt}\n",
    "    _t1 = _timer()\n",
    "    return _t1 - _t0, retval\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = OrderedDict() #keep all measurements here\n",
    "def my_timeit(dict,f,n=10,fname=\"\"):\n",
    "    fname = f.__name__ \n",
    "    dict_name = fname if fname == \"\" else fname\n",
    "    #res = timeit.timeit('s='+fname+'(M)',setup=\"from __main__ import \"+fname+\", M\", number=n)\n",
    "    res, s = timeit.timeit(fname+'(M)',globals=globals(), number=n)\n",
    "    \n",
    "    dict[dict_name] = res/n\n",
    "    print('{0:.3f}'.format(dict[dict_name]))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "For illustration purpose, we are not going to process actual texts, we start from a TF-IDF matrix straing away.\n",
    "Let's generate a matrix similar to what TfidfVectorizer would give us, converted to dense format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_texts = 1018\n",
    "n_words = 14667\n",
    "density = 0.07\n",
    "\n",
    "M = sparse.rand(n_texts, n_words, density).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       ...,\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.466119, 0.      ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the matrix is sparse, but we use it in a dense format. This will work fine for small set of texts\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive approach\n",
    "\n",
    "This is what some one with programming experience, butlittle exposure to python and numpy would come with.\n",
    "Since we need to compare al text to all other texts, we just loop over all texts, and inside that loop we loop again over the remaining text and compute the cosine according to the formula above.\n",
    "Note, that we do not attempt to implement scalar product or vectors norm from scratch - this would not make sence even for a beginner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_matrix(M):\n",
    "    s = np.zeros((len(M),len(M)))\n",
    "\n",
    "    for i in range(len(M)):\n",
    "        iv=M[i]\n",
    "        for j in range(i, len(M)):\n",
    "            jv=M[j]\n",
    "            s[i,j] = np.dot(iv,jv)/norm(iv)/norm(jv)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.373\n"
     ]
    }
   ],
   "source": [
    "s = my_timeit(dict, cos_matrix, n=3, fname=\"naive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.03935207, 0.05498267, ..., 0.05346561, 0.04176018,\n",
       "        0.05739019],\n",
       "       [0.        , 1.        , 0.05328704, ..., 0.04680356, 0.05572377,\n",
       "        0.03870978],\n",
       "       [0.        , 0.        , 1.        , ..., 0.05307461, 0.05030439,\n",
       "        0.04253165],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.06036136,\n",
       "        0.04548421],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.05332369],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cos_matrix', 12.372514069080353)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side note: one can also use `%timeit`  magic allows as to see exactly how much time statement excution took:\n",
    "\n",
    "```\n",
    "%timeit -o s = cos_matrix(M)\n",
    "1 loop, best of 3: 20.2 s per loop\n",
    "```\n",
    "\n",
    "We will ue it when our helper function is not practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the resulting matrix. 1s on the diagonal is expected, as well as 0s below the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1018, 1018)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joblib - parallel execution\n",
    "The second step one could think of is parallel execution. Since computin gcosine difference takes two vertos at a time, it should be trivial to scale it to a number of cores on the box/\n",
    "\n",
    "Python gives a convinient way to parallelize a task via `joblib` package. \n",
    "\n",
    "To start with `joblib` we rewrite our function - the outer loop will be executed `len(M)` times by `joblib` itself, and a resulting vector ofsize `len(M)` will be returned back. Hence we get the same `s` matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def cos_matrix_p(i):\n",
    "    t = np.zeros(len(M))\n",
    "    iv=M[i]\n",
    "    for j in range(i,len(M)):\n",
    "        jv=M[j]\n",
    "        t[j] = np.dot(iv,jv)/norm(iv)/norm(jv)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cos_matrix_p_threading(M):\n",
    "    return Parallel(n_jobs=-1, verbose=1, backend=\"threading\")( map(delayed(cos_matrix_p), range(0,len(M))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1018 out of 1018 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1018 out of 1018 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:  2.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1018 out of 1018 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "s = my_timeit(dict, run_cos_matrix_p_threading, n=3, fname=\"joblib_threading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#res = %timeit -r 2 -o s = Parallel(n_jobs=-1, verbose=1, backend=\"threading\")( map(delayed(cos_matrix_p), range(0,len(M))) )\n",
    "#dict[\"joblib_threading\"] = res.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is dissapointing, but has explanation. Threading in python still uses interpretor and has the GIL as a bottleneck. Effectively, we still use a single OS thread during execution. Thus example is more like a cooperative multitasking than true threading. Besides, there an overhead of passing the data between threads.\n",
    "\n",
    "Let's change the `joblib` backend to 'multiprocessing' that forks separate processes for each parallel task. This way we are sure to use more that one core of a host machine. But bear in mind that overhead of pasing the data between processes will even larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cos_matrix_p_multiprocessing(M):\n",
    "    return Parallel(n_jobs=-1, verbose=1, backend=\"multiprocessing\")( map(delayed(cos_matrix_p), range(0,len(M))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = %timeit -r 3 -o s = Parallel(n_jobs=-1, verbose=1, backend=\"multiprocessing\")( map(delayed(cos_matrix_p), range(0,len(M))))\n",
    "#dict[\"joblib_multiprocessing\"] = res.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1018 out of 1018 | elapsed:   19.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1018 out of 1018 | elapsed:   14.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 799 tasks      | elapsed:   13.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1018 out of 1018 | elapsed:   14.9s finished\n"
     ]
    }
   ],
   "source": [
    "s = my_timeit(dict, run_cos_matrix_p_multiprocessing, n=3, fname=\"joblib_multiprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we got some real improvement! Multicore parallel processing is very useful.\n",
    "Let's make sure the result is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.        , 0.03935207, 0.05498267, ..., 0.05346561, 0.04176018,\n",
       "        0.05739019]),\n",
       " array([0.        , 1.        , 0.05328704, ..., 0.04680356, 0.05572377,\n",
       "        0.03870978]),\n",
       " array([0.        , 0.        , 1.        , ..., 0.05307461, 0.05030439,\n",
       "        0.04253165]),\n",
       " array([0.        , 0.        , 0.        , ..., 0.04484612, 0.04931265,\n",
       "        0.04804116]),\n",
       " array([0.        , 0.        , 0.        , ..., 0.04310505, 0.03313469,\n",
       "        0.05046435])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But can we still do better?\n",
    "\n",
    "Let's check what our function spend time on. We use `%prun` to break down execution time per call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         8818433 function calls in 14.155 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "  1556013    7.118    0.000    7.118    0.000 {built-in method numpy.core.multiarray.dot}\n",
       "  1037342    4.004    0.000   10.098    0.000 linalg.py:2103(norm)\n",
       "        1    1.100    1.100   14.155   14.155 <ipython-input-8-3bec17bbceae>:1(cos_matrix)\n",
       "  1037342    0.774    0.000    0.774    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "  1037342    0.313    0.000    0.313    0.000 {built-in method numpy.core.multiarray.array}\n",
       "  2074684    0.309    0.000    0.309    0.000 {built-in method builtins.issubclass}\n",
       "  1037342    0.280    0.000    0.593    0.000 numeric.py:424(asarray)\n",
       "  1037342    0.249    0.000    0.374    0.000 linalg.py:110(isComplexType)\n",
       "        1    0.008    0.008    0.008    0.008 {built-in method numpy.core.multiarray.zeros}\n",
       "     1021    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
       "        1    0.000    0.000   14.155   14.155 {built-in method builtins.exec}\n",
       "        1    0.000    0.000   14.155   14.155 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = %prun -r  cos_matrix(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         8818433 function calls in 14.155 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  1556013    7.118    0.000    7.118    0.000 {built-in method numpy.core.multiarray.dot}\n",
      "  1037342    4.004    0.000   10.098    0.000 linalg.py:2103(norm)\n",
      "        1    1.100    1.100   14.155   14.155 <ipython-input-8-3bec17bbceae>:1(cos_matrix)\n",
      "  1037342    0.774    0.000    0.774    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "  1037342    0.313    0.000    0.313    0.000 {built-in method numpy.core.multiarray.array}\n",
      "  2074684    0.309    0.000    0.309    0.000 {built-in method builtins.issubclass}\n",
      "  1037342    0.280    0.000    0.593    0.000 numeric.py:424(asarray)\n",
      "  1037342    0.249    0.000    0.374    0.000 linalg.py:110(isComplexType)\n",
      "        1    0.008    0.008    0.008    0.008 {built-in method numpy.core.multiarray.zeros}\n",
      "     1021    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000   14.155   14.155 {built-in method builtins.exec}\n",
      "        1    0.000    0.000   14.155   14.155 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f5420366b00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectedly, `norm()` and `dot()` are the \"winners\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### norm() vs. dot()*dot() \n",
    "\n",
    "Let's make a little trick. `norm()` is a just a square root or scalar product of a vector with itself. Let's get rid of `norm()` in favor of `dot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def norm_dot(iv):\n",
    "    return math.sqrt(np.dot(iv,iv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_matrix_dot_dot(M):\n",
    "    s = np.zeros((len(M),len(M)))\n",
    "\n",
    "    for i in range(len(M)):\n",
    "        iv=M[i]\n",
    "        for j in range(i,len(M)):\n",
    "            jv=M[j]\n",
    "            #s[i,j] = np.dot(iv,jv)/norm(iv)/norm(jv)\n",
    "            s[i,j] = np.dot(iv,jv)/norm_dot(iv)/norm_dot(jv)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.248\n"
     ]
    }
   ],
   "source": [
    "s = my_timeit(dict, cos_matrix_dot_dot, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite unexpectedly, I'd say, we've got a solid improvement from the original run. Why? I don't know for sure. I might suspect that implementation of `dot()` is simpler than that of `norm()` since the latter is more universal - it can calculate a couple of dozens off dirrerent norms, and can also take 2D array of vectors as input. Hence some more general purpose code is executed in `norm()` than we really need in our example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache the norm with LRU\n",
    "\n",
    "Next improvement we can think of is the following. Since we have to calculate `norm()` for the same vector over and over while looping, why not to compute `norm()` once for every vector and memorize the values?\n",
    "\n",
    "Here we use Python's standard `lru_cache` that stands for Least Recently Used and is invoked as a decorator. Note the beauty of this approach - pretty much no code change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "# we have to use integer argument to norm_dot() this time since vectors are not hashable and can't be cache's keys.\n",
    "@lru_cache(maxsize=None)\n",
    "def norm_dot_i(i):\n",
    "    iv = M[i] \n",
    "    return math.sqrt(np.dot(iv,iv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_matrix_dot_dot_cache(M):\n",
    "    s = np.zeros((len(M),len(M)))\n",
    "\n",
    "    for i in range(len(M)):\n",
    "        iv=M[i]\n",
    "        for j in range(i,len(M)):\n",
    "            jv=M[j]\n",
    "            #s[i,j] = np.dot(iv,jv)/norm(iv)/norm(jv)\n",
    "            s[i,j] = np.dot(iv,jv)/norm_dot_i(i)/norm_dot_i(j)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.665\n"
     ]
    }
   ],
   "source": [
    "s = my_timeit(dict, cos_matrix_dot_dot_cache, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectedly better result. But we are still not on par with `joblib` multiprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try some library functions\n",
    "Surely, some one must have done this task before and wanted to come up with an efficient implementaion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy pdist\n",
    "The general task of calculating some function for every pair of given items is known as _pairwise calculation_.\n",
    "ScyPy has a whole set of metrics that can be computed pairwise, and _cosine_ is among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "def cos_matrix_scipy_pdist(M):\n",
    "    return pdist(M, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.647\n"
     ]
    }
   ],
   "source": [
    "y_cosine = my_timeit(dict, cos_matrix_scipy_pdist, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good! But the problem is that the result is flatten into a vector, that we have to somehow turn back to the matrix `s` that we can further use. Not so convinient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517653"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517653.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((len(M)*len(M))-len(M))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn pairwise\n",
    "\n",
    "Scikit-learn gives us two options. One is to calculate cosine similarity directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_matrix_sklearn_cossim(M):\n",
    "    return cosine_similarity(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.03935207, 0.05498267, ..., 0.05346561, 0.04176018,\n",
       "        0.05739019],\n",
       "       [0.03935207, 1.        , 0.05328704, ..., 0.04680356, 0.05572377,\n",
       "        0.03870978],\n",
       "       [0.05498267, 0.05328704, 1.        , ..., 0.05307461, 0.05030439,\n",
       "        0.04253165],\n",
       "       ...,\n",
       "       [0.05346561, 0.04680356, 0.05307461, ..., 1.        , 0.06036136,\n",
       "        0.04548421],\n",
       "       [0.04176018, 0.05572377, 0.05030439, ..., 0.06036136, 1.        ,\n",
       "        0.05332369],\n",
       "       [0.05739019, 0.03870978, 0.04253165, ..., 0.04548421, 0.05332369,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_timeit(dict, cos_matrix_sklearn_cossim, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voilà! We have a new record here! Lets try the other one and then discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_matrix_sklearn_pd_cosine(M):\n",
    "    return pairwise_distances(M, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = %timeit -r 3 -o d = cos_matrix_sklearn_pd_cosine(M)\n",
    "#dict[\"cos_matrix_sklearn_pd_cosine\"] = res.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.164\n"
     ]
    }
   ],
   "source": [
    "d = my_timeit(dict, cos_matrix_sklearn_pd_cosine, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.03935207, 0.05498267, ..., 0.05346561, 0.04176018,\n",
       "        0.05739019],\n",
       "       [0.03935207, 1.        , 0.05328704, ..., 0.04680356, 0.05572377,\n",
       "        0.03870978],\n",
       "       [0.05498267, 0.05328704, 1.        , ..., 0.05307461, 0.05030439,\n",
       "        0.04253165],\n",
       "       [0.06045495, 0.05640413, 0.05417889, ..., 0.04484612, 0.04931265,\n",
       "        0.04804116],\n",
       "       [0.06425379, 0.04670046, 0.06254431, ..., 0.04310505, 0.03313469,\n",
       "        0.05046435]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cosine distance is defined as 1.0 minus cosine similarity.\n",
    "1 - d[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see here is that the less code we write - the better. It means that some task specific functions must have a lot of optimization inside, may even be implemented in _c_ and hence show significant improvement over pure Python. Generally speaking, anything that is implemented without Python loops should be way better than a looped implementation.\n",
    "\n",
    "But we are not done yet..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy is Performance King!\n",
    "\n",
    "Let's implement our function im numpy.\n",
    "We use here:\n",
    "* a feature of `norm()` that can take a vector of vectors, \n",
    "* numpy function `inner()` that calculates values pariwise,\n",
    "* broadcasting rules that allows as get a norm matrix of size len(M),len(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_matrix_np1(M):\n",
    "    n = norm(M,axis=1)\n",
    "    return np.inner(M,M)/(n*n.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.085\n"
     ]
    }
   ],
   "source": [
    "s = my_timeit(dict, cos_matrix_np1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we make a new breaktrhough in performance.\n",
    "Let's play a little trick here again. Replace the `norm()` with a `dot()` - this has proved to work better before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_dot_np(a):\n",
    "    return np.dot(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_matrix_np2(M):\n",
    "    n = np.sqrt(np.apply_along_axis(norm_dot_np,1,M))\n",
    "    return np.inner(M,M)/(n*n.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.067\n"
     ]
    }
   ],
   "source": [
    "s = my_timeit(dict, cos_matrix_np2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.03935207, 0.05498267, ..., 0.05346561, 0.04176018,\n",
       "        0.05739019],\n",
       "       [0.03935207, 1.        , 0.05328704, ..., 0.04680356, 0.05572377,\n",
       "        0.03870978],\n",
       "       [0.05498267, 0.05328704, 1.        , ..., 0.05307461, 0.05030439,\n",
       "        0.04253165],\n",
       "       [0.06045495, 0.05640413, 0.05417889, ..., 0.04484612, 0.04931265,\n",
       "        0.04804116],\n",
       "       [0.06425379, 0.04670046, 0.06254431, ..., 0.04310505, 0.03313469,\n",
       "        0.05046435]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, helped again! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For convinience, use implementations from respected packages.\n",
    "* When have a multicore machine, use `joblib`\n",
    "* For speed, use numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to see how your systems performed agains ours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench1 = OrderedDict([('cos_matrix', 19.840881469969947),\n",
    "             ('run_cos_matrix_p_threading', 25.139403587207198),\n",
    "             ('run_cos_matrix_p_multiprocessing', 1.0726150162518024),\n",
    "             ('cos_matrix_dot_dot', 14.959077935044965),\n",
    "             ('cos_matrix_dot_dot_cache', 9.097761143619815),\n",
    "             ('cos_matrix_scipy_pdist', 7.121200116351247),\n",
    "             ('cos_matrix_sklearn_cossim', 0.31781461276113987),\n",
    "             ('cos_matrix_sklearn_pd_cosine', 0.32281870637089016),\n",
    "             ('cos_matrix_np1', 0.17069526184350253),\n",
    "             ('cos_matrix_np2', 0.09111224306747318)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench2 = OrderedDict([('cos_matrix', 12.372514069080353),\n",
    "             ('run_cos_matrix_p_threading', 101.84953497412305),\n",
    "             ('run_cos_matrix_p_multiprocessing', 16.79279000808795),\n",
    "             ('cos_matrix_dot_dot', 8.24763044094046),\n",
    "             ('cos_matrix_dot_dot_cache', 3.6650888534883657),\n",
    "             ('cos_matrix_scipy_pdist', 7.646780099719763),\n",
    "             ('cos_matrix_sklearn_cossim', 0.17296662777662278),\n",
    "             ('cos_matrix_sklearn_pd_cosine', 0.16396221406757833),\n",
    "             ('cos_matrix_np1', 0.08530212858691812),\n",
    "             ('cos_matrix_np2', 0.06693178607150913)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "benchmark = pd.DataFrame({\"E2690v4 python3.6 vanilla\":bench1,\n",
    "                          \"E2690v4 python3.6 anaconda\":bench2,\n",
    "                          \"Your System\": dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E2690v4 python3.6 anaconda</th>\n",
       "      <th>E2690v4 python3.6 vanilla</th>\n",
       "      <th>Your System</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>run_cos_matrix_p_threading</th>\n",
       "      <td>101.849535</td>\n",
       "      <td>25.139404</td>\n",
       "      <td>101.849535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_cos_matrix_p_multiprocessing</th>\n",
       "      <td>16.792790</td>\n",
       "      <td>1.072615</td>\n",
       "      <td>16.792790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_matrix</th>\n",
       "      <td>12.372514</td>\n",
       "      <td>19.840881</td>\n",
       "      <td>12.372514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_matrix_dot_dot</th>\n",
       "      <td>8.247630</td>\n",
       "      <td>14.959078</td>\n",
       "      <td>8.247630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_matrix_scipy_pdist</th>\n",
       "      <td>7.646780</td>\n",
       "      <td>7.121200</td>\n",
       "      <td>7.646780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_matrix_dot_dot_cache</th>\n",
       "      <td>3.665089</td>\n",
       "      <td>9.097761</td>\n",
       "      <td>3.665089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_matrix_sklearn_cossim</th>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.317815</td>\n",
       "      <td>0.172967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_matrix_sklearn_pd_cosine</th>\n",
       "      <td>0.163962</td>\n",
       "      <td>0.322819</td>\n",
       "      <td>0.163962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_matrix_np1</th>\n",
       "      <td>0.085302</td>\n",
       "      <td>0.170695</td>\n",
       "      <td>0.085302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_matrix_np2</th>\n",
       "      <td>0.066932</td>\n",
       "      <td>0.091112</td>\n",
       "      <td>0.066932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  E2690v4 python3.6 anaconda  \\\n",
       "run_cos_matrix_p_threading                        101.849535   \n",
       "run_cos_matrix_p_multiprocessing                   16.792790   \n",
       "cos_matrix                                         12.372514   \n",
       "cos_matrix_dot_dot                                  8.247630   \n",
       "cos_matrix_scipy_pdist                              7.646780   \n",
       "cos_matrix_dot_dot_cache                            3.665089   \n",
       "cos_matrix_sklearn_cossim                           0.172967   \n",
       "cos_matrix_sklearn_pd_cosine                        0.163962   \n",
       "cos_matrix_np1                                      0.085302   \n",
       "cos_matrix_np2                                      0.066932   \n",
       "\n",
       "                                  E2690v4 python3.6 vanilla  Your System  \n",
       "run_cos_matrix_p_threading                        25.139404   101.849535  \n",
       "run_cos_matrix_p_multiprocessing                   1.072615    16.792790  \n",
       "cos_matrix                                        19.840881    12.372514  \n",
       "cos_matrix_dot_dot                                14.959078     8.247630  \n",
       "cos_matrix_scipy_pdist                             7.121200     7.646780  \n",
       "cos_matrix_dot_dot_cache                           9.097761     3.665089  \n",
       "cos_matrix_sklearn_cossim                          0.317815     0.172967  \n",
       "cos_matrix_sklearn_pd_cosine                       0.322819     0.163962  \n",
       "cos_matrix_np1                                     0.170695     0.085302  \n",
       "cos_matrix_np2                                     0.091112     0.066932  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.sort_values(by=benchmark.columns[0], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final thoughts: it's OK to Google it!\n",
    "\n",
    "Python, scipy and sklearn ecosystem is *huge*. It's virtually impossible to read the whole doc and then say: \"Ok, I got it\". People google for anwers all time and collect brilliant ideas from Stackoverflow and other sites. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
